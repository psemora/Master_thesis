{"cells":[{"cell_type":"markdown","source":["**Connect google drive**"],"metadata":{"id":"M3uxd9Z0iRIH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXm1ZUoc9X1K"},"outputs":[],"source":["# Check if NVIDIA GPU is enabled\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1QwLcfo99pW"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**1) Install and import libraries**"],"metadata":{"id":"AjLeoMoji-0W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tvd8aLx49mzT"},"outputs":[],"source":["#Install libraries\n","!pip install segmentation_models\n","!pip install -U albumentations\n","!pip install pyyaml h5py\n","!pip install tensorflow==2.3.0\n","!pip install opencv-python-headless==4.5.2.52\n","!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aBIz0R21-BmG"},"outputs":[],"source":["#Import libraries\n","%env SM_FRAMEWORK = tf.keras\n","import numpy as np\n","from glob import glob \n","import cv2 \n","import segmentation_models as sm\n","import matplotlib.pyplot as plt\n","import random\n","import albumentations as A\n","from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam, Adadelta, Adagrad, SGD, Nadam, schedules\n","from  segmentation_models.metrics import iou_score\n","from google.colab.patches import cv2_imshow\n","from natsort import natsorted\n","from IPython.display import clear_output\n","from tensorflow import keras\n","\n","np.set_printoptions(threshold=np.inf)"]},{"cell_type":"code","source":["#Define backbone (encoder architecture) and batch_size\n","BACKBONE = 'seresnet34'\n","preprocess_input = sm.get_preprocessing(BACKBONE)\n","batch_size = 16"],"metadata":{"id":"rtDKIknOkrQY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2) Load and preprocess dataset**"],"metadata":{"id":"XbznzZk_pjEh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvp5ikYwrYRp"},"outputs":[],"source":["#Load images\n","def load_data(pi, pl):\n","  obj_im = []\n","  obj_la = []\n","  for file in natsorted(glob(pi+'/*.*')):\n","    img = cv2.imread(file, cv2.COLOR_BGR2RGB)\n","    obj_im.append(img)\n","\n","  for file in natsorted(glob(pl+'/*.*')):\n","    lab = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n","    obj_la.append(lab)\n","    \n","  return np.asarray(obj_im), np.asarray(obj_la)\n","#Load train images and masks from \"train\" and \"train_masks\" folders in \"dataset\" folder on Google drive\n","x_train, y_train = load_data('drive/MyDrive/dataset/train', 'drive/MyDrive/dataset/train_masks')\n","#Load validation images and masks from \"valid\" and \"valid_masks\" folders in \"dataset\" folder on Google drive\n","x_valid, y_valid = load_data('drive/MyDrive/dataset/valid', 'drive/MyDrive/dataset/valid_masks')\n","\n","x_train = preprocess_input(x_train)\n","x_valid = preprocess_input(x_valid)\n","\n","#Check if dataset is loaded corretly\n","print('x_train', x_train.shape)\n","print('y_train', y_train.shape)\n","print()\n","print('x_valid', x_valid.shape)\n","print('y_valid', y_valid.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pbYcy19V-ny"},"outputs":[],"source":["#Load testing images from \"test\" folder in \"dataset\" folder on Google drive\n","def load_test(pi):\n","  obj_im = []\n","  for file in natsorted(glob(pi+'/*.*')):\n","      img = cv2.imread(file, cv2.COLOR_BGR2RGB)\n","      obj_im.append(img)\n","  return np.asarray(obj_im)\n","\n","x_test = load_test('drive/MyDrive/dataset/test')\n","print('x_test', x_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WmB82X5-er_"},"outputs":[],"source":["#Show if images and masks are loaded correctly\n","index = 15\n","cv2_imshow(x_train[index])\n","#plt.imshow(x_train[index].astype('int'))\n","#plt.show()\n","\n","cv2_imshow(y_train[index])\n","print(np.unique(y_train[index],return_counts=True)) #Mask should contain only binary pixels [0,255] \n","#plt.imshow(y_train[index].astype('int'))\n","#plt.show()"]},{"cell_type":"markdown","source":["**3) Augmentation**"],"metadata":{"id":"IV0AYMS2sKkn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yq_D88Hh-iJL"},"outputs":[],"source":["# Generated from: https://albumentations-demo.herokuapp.com/\n","\n","def augment_albu(image, mask):   \n","    #STŘEDNÍ\n","    t = A.Compose([\n","        A.Blur(always_apply=False, p=0.5, blur_limit=(3, 6)),\n","        A.Posterize(always_apply=False, p=0.4, num_bits=[(0, 7), (0, 7), (0, 7)]),\n","        A.ToSepia(always_apply=False, p=0.4),\n","        A.HorizontalFlip(always_apply=False, p=0.5),\n","        A.RandomResizedCrop(always_apply=False, p=0.5, height=320, width=480, scale=(0.7, 0.8), ratio=(0.75, 1.3), interpolation=0),\n","        A.OneOf([\n","          A.HueSaturationValue(always_apply=True, hue_shift_limit=(-20, 20), sat_shift_limit=(-30, 30), val_shift_limit=(-20, 20)),\n","          A.RandomContrast(always_apply=True, limit=(-0.5, 0.2)),\n","          A.RGBShift(always_apply=True, r_shift_limit=(-20, 20), g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),    \n","                ],p=1,),\n","        ])\n","    \n","    aug = t(image=image, mask=mask)\n","\n","    return aug['image'], aug['mask']"]},{"cell_type":"markdown","source":["**4) Data generator**"],"metadata":{"id":"K43QzpTItM4c"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"13jSpTx6-lKk"},"outputs":[],"source":["def data_generator(augment):\n","    while True:\n","        g_images = []\n","        g_labels = []\n","\n","        for b in range(batch_size):\n","            if augment:\n","                index = random.randrange(0, len(x_train))\n","                g_im, g_la = augment_albu(x_train[index], y_train[index])\n","\n","            else:\n","                index = random.randrange(0, len(x_valid))\n","                g_im, g_la = x_valid[index], y_valid[index]\n","\n","            g_la = [(g_la==v) for v in [0,255]]\n","            g_la = np.stack(g_la, axis=-1)\n","          \n","            g_images.append(g_im)\n","            g_labels.append(g_la)\n","\n","        g_images = np.asarray(g_images)\n","        g_labels = np.asarray(g_labels)\n","\n","        yield g_images.astype('float32'), g_labels.astype('float32')\n","\n","def gen_train():\n","  #Train data are augmented\n","    return data_generator(True)\n","    \n","def gen_val():\n","  #Valid data are not augmented\n","    return data_generator(False)"]},{"cell_type":"markdown","source":["**5) Weights and Biases**"],"metadata":{"id":"2mrKDNpMvPe1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZp2xBKBEgCf"},"outputs":[],"source":["#Import, login and init W&B platform for train tracking and displaying graphs during training\n","import os\n","os.environ[\"WANDB_START_METHOD\"] = \"thread\"\n","import wandb\n","from wandb.keras import WandbCallback\n","wandb.login()\n","wandb.init(project=\"Final\", entity=\"your_entity\")\n","wandb.run.name = \"model1\""]},{"cell_type":"markdown","source":["**6) Callbacks define**"],"metadata":{"id":"03nJ8pr_xyMw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QpLXO9Af9qI"},"outputs":[],"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    #clear_output(wait=True)\n","    show_predictions_callback()\n","\n","#Dynamic reduce learning rate of optimizer    \n","reduce_lr = ReduceLROnPlateau(monitor='loss', patience=2, factor=0.5, verbose=1)\n","\n","#Save best model during training\n","checkpoint_filepath = \"/content/drive/MyDrive/best_model.h5\"\n","model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=False, save_best_only=True, monitor='val_loss', verbose=1, mode='min')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O-90ANds_Wbd"},"outputs":[],"source":["def show_predictions_callback():\n","  index = 1\n","  image = x_test[index]\n","  \n","  #Show image\n","  cv2_imshow(image)\n","\n","  #Show predicted mask\n","  image = preprocess_input(image)\n","  image = np.expand_dims(image, axis = 0)\n","  pred = model.predict(image)[0]\n","  pred = np.argmax(pred,axis = -1)\n","  pred = pred.astype(np.float32)*255\n","  print(np.unique(pred,return_counts=True))\n","  cv2_imshow(pred)"]},{"cell_type":"markdown","source":["**6) Define model and start training**"],"metadata":{"id":"q7GbkBj6yomK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ES3QQ6JN-vJb"},"outputs":[],"source":["#Build model\n","model = sm.Unet(backbone_name=BACKBONE, classes=2, encoder_weights='imagenet', input_shape=(320, 480, 3), activation='sigmoid')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oxy9jHhUVJcR"},"outputs":[],"source":["#Compile model\n","model.compile(Adam(), 'binary_crossentropy', metrics= [iou_score])\n","#Show model\n","#model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndHll02q-7jB"},"outputs":[],"source":["#Start training\n","model_history = model.fit(gen_train(), \n","                          validation_data=gen_val(), \n","                          steps_per_epoch=200, \n","                          validation_steps=100, \n","                          batch_size=batch_size, \n","                          epochs=10, \n","                          callbacks=[reduce_lr, wandb.keras.WandbCallback(), model_checkpoint_callback, DisplayCallback()])\n","#Save model after run is done\n","model.save(\"/content/drive/MyDrive/model1.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlA_OX3_9Hgm"},"outputs":[],"source":["#Finish transfer to W&B after run is done\n","wandb.finish() "]},{"cell_type":"markdown","source":["**7) Evaluate trained models**"],"metadata":{"id":"LAoaHlrf0UaR"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Yy6664bpV75G"},"outputs":[],"source":["#Load Models:\n","model1 = tf.keras.models.load_model('/content/drive/MyDrive/model1.h5', compile=False)\n","model2 = tf.keras.models.load_model('/content/drive/MyDrive/model2.h5', compile=False)\n","model3 = tf.keras.models.load_model('/content/drive/MyDrive/model3.h5', compile=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EWt1ObJZ3b4T"},"outputs":[],"source":["#For models ensemble\n","models = []\n","models.append(model1)\n","models.append(model2)\n","models.append(model3)"]},{"cell_type":"code","source":["#Models evaluating on valid images and comparing with ground truth masks\n","def show_predictions(index):\n","  #Show image\n","  print(\"Valid image:\" ,index)\n","  img = cv.cvtColor(x_valid[index], cv.COLOR_BGR2RGB)\n","  plt.imshow(img.astype('int'))\n","  plt.show()\n","  \n","  #Show mask\n","  print(\"Ground truth mask:\")\n","  mask = (y_valid[index]).astype(np.uint8)\n","  mask = cv.cvtColor(mask, cv.COLOR_BGR2RGB)\n","  print(np.unique(y_valid[index],return_counts=True))\n","  plt.imshow(mask)\n","  plt.show()\n","\n","  #Preprocess for prediction\n","  image = x_valid[index]\n","  image = preprocess_input(image)\n","  image = np.expand_dims(image, axis = 0)\n","  \n","  #Model1 prediction\n","  print(\"model 1:\")\n","  pred_raw = model.predict(image)[0]\n","  pred = np.argmax(pred_raw,axis = -1)\n","  pred = (pred*255).astype(np.uint8)\n","  pred = cv.cvtColor(pred, cv.COLOR_BGR2RGB)\n","  print(np.unique(pred,return_counts=True))\n","  plt.imshow(pred)\n","  plt.show()\n","  \n","  #Model2 prediction\n","  print(\"model 2:\")\n","  pred2_raw = model2.predict(image)[0]\n","  pred2 = np.argmax(pred2_raw,axis = -1)\n","  pred2 = (pred2*255).astype(np.uint8)\n","  pred2 = cv.cvtColor(pred2, cv.COLOR_BGR2RGB)\n","  print(np.unique(pred2,return_counts=True))\n","  plt.imshow(pred2)\n","  plt.show()\n","  \n","  #Model3 prediction\n","  print(\"model 3:\")\n","  pred3_raw = model3.predict(image)[0]\n","  pred3 = np.argmax(pred3_raw,axis = -1)\n","  pred3 = (pred3*255).astype(np.uint8)\n","  pred3 = cv.cvtColor(pred3, cv.COLOR_BGR2RGB)\n","  print(np.unique(pred3,return_counts=True))\n","  plt.imshow(pred3)\n","  plt.show()\n","\n","  #Ensemble models prediction\n","  preds=np.array([pred_raw, pred2_raw, pred3_raw])\n","  weights = [1,1,1]\n","  #Use tensordot to sum the products of all elements over specified axes.\n","  weighted_preds = np.tensordot(preds, weights, axes=((0),(0)))\n","  weighted_ensemble_prediction = np.argmax(weighted_preds, axis=-1)\n","  ensemble_pred = (weighted_ensemble_prediction*255).astype(np.uint8)\n","  ensemble_pred = cv.cvtColor(ensemble_pred, cv.COLOR_BGR2RGB)\n","  print(\"[INFO] Predicted ensemble Mask:\",np.unique(ensemble_pred,return_counts=True))\n","  plt.imshow(ensemble_pred)\n","  plt.show()\n","\n","index = 1\n","show_predictions(index)"],"metadata":{"id":"fRWz0jbu4rPa"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8zX7gzgWcre"},"outputs":[],"source":["#Models evaluating on test images\n","def show_predictions(index):\n","  #Show image:\n","  print(\"Image:\" ,index)\n","  img = cv2.cvtColor(x_test[index], cv2.COLOR_BGR2RGB)\n","  plt.imshow(img.astype('int'))\n","  plt.show()\n","\n","  #Preprocess for prediction\n","  image = x_test[index]\n","  image = preprocess_input(image)\n","  image = np.expand_dims(image, axis = 0)\n","  \n","  #Model1 prediction:\n","  print(\"model 1:\")\n","  pred_raw = model.predict(image)[0]\n","  pred = np.argmax(pred_raw,axis = -1)\n","  pred = (pred*255).astype(np.uint8)\n","  pred = cv2.cvtColor(pred, cv2.COLOR_BGR2RGB)\n","  print(np.unique(pred,return_counts=True))\n","  plt.imshow(pred)\n","  plt.show()\n","  \n","  #Model2 prediction:\n","  print(\"model 2:\")\n","  pred2_raw = model2.predict(image)[0]\n","  pred2 = np.argmax(pred2_raw,axis = -1)\n","  pred2 = (pred2*255).astype(np.uint8)\n","  pred2 = cv.cvtColor(pred2, cv.COLOR_BGR2RGB)\n","  print(np.unique(pred2,return_counts=True))\n","  plt.imshow(pred2)\n","  plt.show()\n","\n","  #Model3 prediction:\n","  print(\"model 3:\")\n","  pred3_raw = model3.predict(image)[0]\n","  pred3 = np.argmax(pred3_raw,axis = -1)\n","  pred3 = (pred3*255).astype(np.uint8)\n","  pred3 = cv.cvtColor(pred3, cv.COLOR_BGR2RGB)\n","  print(np.unique(pred3,return_counts=True))\n","  plt.imshow(pred3)\n","  plt.show()\n","\n","  #Ensemble models prediction\n","  preds=np.array([pred_raw, pred2_raw, pred3_raw])\n","  weights = [1,1,1]\n","  #Use tensordot to sum the products of all elements over specified axes.\n","  weighted_preds = np.tensordot(preds, weights, axes=((0),(0)))\n","  weighted_ensemble_prediction = np.argmax(weighted_preds, axis=-1)\n","  ensemble_pred = (weighted_ensemble_prediction*255).astype(np.uint8)\n","  ensemble_pred = cv.cvtColor(ensemble_pred, cv.COLOR_BGR2RGB)\n","  print(\"[INFO] Predicted ensemble Mask:\",np.unique(ensemble_pred,return_counts=True))\n","  plt.imshow(ensemble_pred)\n","  plt.show()\n","\n","index = 1\n","show_predictions(index)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DP_segmentace.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}